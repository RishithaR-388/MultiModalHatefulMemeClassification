DATASET : harm
FEW_SHOT : False
FINE_GRIND : False
NUM_SHOTS : 16
MODEL : pbm
UNIMODAL : False
DATA : /Data_Storage/Rui_Data_Space/textual/hate-speech
CAPTION_PATH : /Data_Storage/Rui_Code_Space/NLP/textual/hate-speech/clip-kb/CLIP_prefix_caption
RESULT : ./result
FEAT_DIM : 2048
CLIP_DIM : 512
BERT_DIM : 768
ROBERTA_DIM : 1024
NUM_FOLD : 5
EMB_DIM : 300
NUM_LABELS : 2
POS_WORD : good
NEG_WORD : bad
DEM_SAMP : False
SIM_RATE : 0.5
IMG_RATE : 0.5
TEXT_RATE : 0.5
CLIP_CLEAN : False
MULTI_QUERY : True
NUM_QUERIES : 4
EMB_DROPOUT : 0.0
FC_DROPOUT : 0.4
WEIGHT_DECAY : 0.01
LR_RATE : 1e-05
EPS : 1e-08
BATCH_SIZE : 16
FIX_LAYERS : 0
MID_DIM : 512
NUM_HIDDEN : 512
LENGTH : 64
TOTAL_LENGTH : 256
PREFIX_LENGTH : 10
NUM_SAMPLE : 1
NUM_LAYER : 8
MODEL_NAME : roberta-large
PRETRAIN_DATA : conceptual
IMG_VERSION : clean
MAPPING_TYPE : transformer
ADD_ENT : True
ADD_DEM : True
DEBUG : False
SAVE : False
SAVE_NUM : 7
EPOCHS : 10
SEED : 1117
CUDA_DEVICE : 12
WARM_UP : 2000
TRANS_LAYER : 1
NUM_HEAD : 8
Length of training set: 3013, length of testing set: 354
Epoch 0
	train_loss: 522.62, accuracy: 65.22
	evaluation auc: 85.60, accuracy: 79.66
Epoch 1
	train_loss: 198.02, accuracy: 76.17
	evaluation auc: 91.46, accuracy: 86.16
Epoch 2
	train_loss: 165.95, accuracy: 80.78
	evaluation auc: 91.38, accuracy: 85.03
Epoch 3
	train_loss: 141.46, accuracy: 83.74
	evaluation auc: 90.16, accuracy: 80.51
Epoch 4
	train_loss: 120.84, accuracy: 86.86
	evaluation auc: 90.57, accuracy: 82.49
Epoch 5
	train_loss: 90.60, accuracy: 90.04
	evaluation auc: 89.97, accuracy: 81.36
Epoch 6
	train_loss: 70.47, accuracy: 92.63
	evaluation auc: 89.90, accuracy: 82.20
Epoch 7
	train_loss: 46.80, accuracy: 95.78
	evaluation auc: 88.91, accuracy: 79.94
Epoch 8
	train_loss: 32.22, accuracy: 96.71
	evaluation auc: 89.06, accuracy: 81.07
Epoch 9
	train_loss: 22.17, accuracy: 97.94
	evaluation auc: 87.90, accuracy: 79.10
Maximum epoch: 1
	evaluation auc: 91.46, accuracy: 86.16
